# Group6_CSCE5290
Natural Language Processing Project

Toxic comments affect the mental well-being of many internet users. Currently, there exist some tools to filter toxic comments online, but their accuracy has room for improvement, and few can differentiate multiple levels of toxicity. We seek to train a model with Charformer that can detect the level of toxicity in comments with high accuracy. This may help those constricted by negative comments to feel more comfortable browsing and sharing on the internet. We are using training data from Kaggle’s “Toxic Comment Classification Challenge”, with the goal of out-performing the standard Bert model, which already does an adequate toxic classification job.

The Jupyter notebook within this github contains all our code for both the new Toxic comment model and our previous Swedish/English translation model.
